{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_preds = pd.read_csv('pred_y.csv')\n",
    "Y_preds['alg'] = Y_preds['alg'].str.replace('deep ', 'deep$')\n",
    "Y_preds['alg'] = Y_preds['alg'].str.replace('Neural Net SVM ', 'Neural Net SVM$')\n",
    "Y_preds[['clf','alg_matcher']] = Y_preds['alg'].str.split('$', expand=True)\n",
    "Y_preds = Y_preds.drop(['alg', 'Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_preds = pd.read_csv('pred_eval.csv')\n",
    "eval_preds['P_hat'] = eval_preds['P_hat'].str.replace('[', '').str.replace(']', '').astype(float)\n",
    "eval_preds['F_hat'] = eval_preds['F_hat'].str.replace('[', '').str.replace(']', '').astype(float)\n",
    "eval_preds['alg'] = eval_preds['alg'].str.replace('deep ', 'deep$')\n",
    "eval_preds['alg'] = eval_preds['alg'].str.replace('SVM ', 'SVM$')\n",
    "eval_preds[['reg','alg_matcher']] = eval_preds['alg'].str.split('$', expand=True)\n",
    "eval_preds = eval_preds.drop(['alg', 'Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(left=Y_preds, right=eval_preds)\n",
    "df['alg'] = [' '.join(i) for i in zip(df['alg_matcher'].map(str), df['clf'], df['reg'])]\n",
    "alg_matches = pd.read_csv('../../algs.csv')\n",
    "labels = pd.read_csv('../../Excel2CIDX.csv', header = None, names = ['candName', 'targName', 'real'])\n",
    "labels['correspondence'] = list(zip(labels.targName.str.replace(' ', ''), labels.candName.str.replace(' ', '')))\n",
    "labels['correspondence'] = labels['correspondence'].astype(str)\n",
    "alg_matches['correspondence'] = list(zip(alg_matches.targName, alg_matches.candName))\n",
    "alg_matches['correspondence'] = alg_matches['correspondence'].astype(str)\n",
    "alg_matches = alg_matches.merge(labels[['correspondence', 'real']], how='left', on = 'correspondence').fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(df, name):\n",
    "    matchers = df['matcher'].unique().tolist()\n",
    "    algs = df['alg'].unique().tolist()\n",
    "    all_correct = 65\n",
    "    res = pd.DataFrame(columns=['Algorithmic Matcher', 'Classifier', 'Regressor', 'matcher', 'P', 'R', 'F'])\n",
    "    row_i = 1\n",
    "    for alg in algs:\n",
    "        if not alg:\n",
    "            continue\n",
    "        for matcher in matchers:\n",
    "            sum_correct = len(df[(df['alg'] == alg)\n",
    "                                 & (df['matcher'] == matcher)\n",
    "                                 & (df['pred'] == df['real'])\n",
    "                                 & (df['real'] == 1)])\n",
    "            sum_answered = len(df[(df['alg'] == alg)\n",
    "                                 & (df['matcher'] == matcher)\n",
    "                                 & (df['pred'] == 1)])\n",
    "            P = sum_correct/sum_answered if sum_answered > 0 else np.nan\n",
    "            R = sum_correct/all_correct\n",
    "            F = (2*P*R)/(P+R) if (P+R) > 0 else np.nan\n",
    "            alg_matcher = df.loc[(df['alg'] == alg) & (df['matcher'] == matcher), 'alg_matcher'].tolist()[0]\n",
    "            clf = df.loc[(df['alg'] == alg) & (df['matcher'] == matcher), 'clf'].tolist()[0]\n",
    "            reg = df.loc[(df['alg'] == alg) & (df['matcher'] == matcher), 'reg'].tolist()[0]\n",
    "            res.loc[row_i] = np.array([alg_matcher,\n",
    "                                       clf,\n",
    "                                       reg,\n",
    "                                       matcher,\n",
    "                                       P,\n",
    "                                       R,\n",
    "                                       F])\n",
    "            row_i += 1\n",
    "        res[['P','R','F']]=res[['P','R','F']].astype(float)\n",
    "        pd.DataFrame(res.groupby(['1LM + 2LM', 'Classifier', 'Regressor'])[['P','R','F']].mean()).to_csv('res/' +name+ '.csv')\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unbaised Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_conf = df.loc[df['alg'] == 'Ontobuilder Term Match Neural Net SVM SVM', ['matcher', 'correspondence', 'conf', 'real']]\n",
    "# df_conf['index'] = df_conf.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_conf = df_conf.assign(decision_count = df_conf.groupby('matcher')['conf'].transform('count'))\n",
    "# df_conf['conf_sum'] = df_conf['conf']\n",
    "# sum_confs = df_conf.groupby(['matcher', 'index'])['conf_sum'].sum().groupby(level=0).cumsum().reset_index().set_index(['index'])\n",
    "# df_conf = df_conf.drop(['conf_sum', 'matcher'], axis = 1)\n",
    "# df_conf = pd.merge(left=df_conf, right=sum_confs, on = ['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_conf['pred_recall'] = 1\n",
    "# df_conf['pred_P_static'] = 0\n",
    "# df_conf.loc[df_conf['conf'] >= 1.0, 'pred_P_static'] = 1\n",
    "# df_conf['pred_F_static'] = 0\n",
    "# df_conf.loc[df_conf['conf'] >= 0.5, 'pred_F_static'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matchers = df_conf['matcher'].unique().tolist()\n",
    "# df_conf['pred_P_dynamic'] = 0\n",
    "# df_conf['pred_F_dynamic'] = 0\n",
    "# for m in matchers:\n",
    "#     H = df_conf[df_conf['matcher'] == m]\n",
    "#     sum_conf_P = 0\n",
    "#     match_size_P = 0\n",
    "#     sum_conf_F = 0\n",
    "#     match_size_F = 0\n",
    "#     all_correct = 65\n",
    "#     for _, h in H.iterrows():\n",
    "#         curr_P = sum_conf_P/match_size_P if match_size_P > 0 else 0.0\n",
    "#         curr_F = (2*sum_conf_F)/(match_size_F + all_correct)\n",
    "#         if h['conf'] >= curr_P:\n",
    "#             df_conf.loc[df_conf['index'] == h['index'], 'pred_P_dynamic'] = 1\n",
    "#             sum_conf_P += h['conf'] \n",
    "#             match_size_P += 1\n",
    "#         if h['conf'] >= 0.5*curr_F:\n",
    "#             df_conf.loc[df_conf['index'] == h['index'], 'pred_F_dynamic'] = 1\n",
    "#             sum_conf_F += h['conf'] \n",
    "#             match_size_F += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_conf['alg'] = 'dummy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unbiased_target_R = evaluate(df_conf.rename(columns={'pred_recall': 'pred'}), 'unbiased_target_R')\n",
    "# unbiased_target_P_static = evaluate(df_conf.rename(columns={'pred_P_static': 'pred'}), 'unbiased_target_P_static')\n",
    "# unbiased_target_F_static = evaluate(df_conf.rename(columns={'pred_F_static': 'pred'}), 'unbiased_target_F_static')\n",
    "# unbiased_target_P_dynamic = evaluate(df_conf.rename(columns={'pred_P_dynamic': 'pred'}), 'unbiased_target_P_dynamic')\n",
    "# unbiased_target_F_dynamic = evaluate(df_conf.rename(columns={'pred_F_dynamic': 'pred'}), 'unbiased_target_F_dynamic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# History Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hp = df.copy()\n",
    "df_hp = df_hp[df_hp['matcher'] == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hp['pred_R'] = 1\n",
    "df_hp['pred_P_static'] = 0\n",
    "df_hp.loc[df_hp['pred_conf'] >= 0.95, 'pred_P_static'] = 1\n",
    "df_hp['pred_F_static'] = 0\n",
    "df_hp.loc[df_hp['pred_conf'] >= 0.5, 'pred_F_static'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_vanila = evaluate(df_hp, 'vanila')\n",
    "hp_target_R = evaluate(df_hp.rename(columns={'pred': 'temp', 'pred_R': 'pred'}), 'hp_pred_R')\n",
    "hp_target_P_static = evaluate(df_hp.rename(columns={'pred': 'temp', 'pred_P_static': 'pred'}), 'hp_target_P_static')\n",
    "hp_target_F_static = evaluate(df_hp.rename(columns={'pred': 'temp', 'pred_F_static': 'pred'}), 'hp_target_F_static')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hp['pred_P_dynamic'] = 0\n",
    "df_hp.loc[df_hp['pred_conf'] >= df_hp['P_hat'], 'pred_P_dynamic'] = 1\n",
    "df_hp['pred_F_dynamic'] = 0\n",
    "df_hp.loc[df_hp['pred_conf'] >= 0.5*df_hp['F_hat'], 'pred_F_dynamic'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_target_P_dynamic = evaluate(df_hp.rename(columns={'pred': 'temp', 'pred_P_dynamic': 'pred'}), 'hp_target_P_dynamic')\n",
    "hp_target_F_dynamic = evaluate(df_hp.rename(columns={'pred': 'temp', 'pred_F_dynamic': 'pred'}), 'hp_target_F_dynamic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hp['pred_P_real'] = 0\n",
    "df_hp.loc[df_hp['pred_conf'] >= df_hp['P_hat'], 'pred_P_real'] = 1\n",
    "df_hp['pred_F_real'] = 0\n",
    "df_hp.loc[df_hp['pred_conf'] >= 0.5*df_hp['F_hat'], 'pred_F_real'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_target_P_real = evaluate(df_hp.rename(columns={'pred': 'temp', 'pred_P_real': 'pred'}), 'hp_target_P_real')\n",
    "hp_target_F_real = evaluate(df_hp.rename(columns={'pred': 'temp', 'pred_F_real': 'pred'}), 'hp_target_F_real')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recall Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matchers = df_hp['matcher'].unique().tolist()\n",
    "algs = df_hp['alg_matcher'].unique().tolist()\n",
    "df_rb_th = {}\n",
    "df_rb_maxd = {}\n",
    "df_rb_maxdcol = {}\n",
    "df_rb_dom = {}\n",
    "# R is 0.0, F is 0.5, and P is 1.0\n",
    "thresholds = np.linspace(0.0, 1.0, num=11)\n",
    "thresholds[0] = 0.001\n",
    "thresholds = [0, ] + [round(t, 1) for t in thresholds] + [1.001, ]\n",
    "for num in thresholds:\n",
    "    df_rb_th[str(num)] = pd.DataFrame(columns=df_hp.columns)\n",
    "    df_rb_maxd[str(num)] = pd.DataFrame(columns=df_hp.columns)\n",
    "    df_rb_maxdcol[str(num)] = pd.DataFrame(columns=df_hp.columns)\n",
    "    df_rb_dom[str(num)] = pd.DataFrame(columns=df_hp.columns)\n",
    "df_rb_th['P_dynamic'] = pd.DataFrame(columns=df_hp.columns)\n",
    "df_rb_th['F_dynamic'] = pd.DataFrame(columns=df_hp.columns)\n",
    "df_rb_maxd['P_dynamic'] = pd.DataFrame(columns=df_hp.columns)\n",
    "df_rb_maxd['F_dynamic'] = pd.DataFrame(columns=df_hp.columns)\n",
    "df_rb_maxdcol['P_dynamic'] = pd.DataFrame(columns=df_hp.columns)\n",
    "df_rb_maxdcol['F_dynamic'] = pd.DataFrame(columns=df_hp.columns)\n",
    "df_rb_dom['P_dynamic'] = pd.DataFrame(columns=df_hp.columns)\n",
    "df_rb_dom['F_dynamic'] = pd.DataFrame(columns=df_hp.columns)\n",
    "df_rb_th['P_real'] = pd.DataFrame(columns=df_hp.columns)\n",
    "df_rb_th['F_real'] = pd.DataFrame(columns=df_hp.columns)\n",
    "df_rb_maxd['P_real'] = pd.DataFrame(columns=df_hp.columns)\n",
    "df_rb_maxd['F_real'] = pd.DataFrame(columns=df_hp.columns)\n",
    "df_rb_maxdcol['P_real'] = pd.DataFrame(columns=df_hp.columns)\n",
    "df_rb_maxdcol['F_real'] = pd.DataFrame(columns=df_hp.columns)\n",
    "df_rb_dom['P_real'] = pd.DataFrame(columns=df_hp.columns)\n",
    "df_rb_dom['F_real'] = pd.DataFrame(columns=df_hp.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_cols = [col for col in df_hp.columns.tolist() if col not in ['correspondence', 'real']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for alg in algs:\n",
    "    if alg == 'all':\n",
    "        alg = 'Ontobuilder Term Match'\n",
    "    print(alg)\n",
    "    for matcher in matchers:\n",
    "#         SETUP:\n",
    "        answered = df_hp[(df_hp['alg_matcher'] == alg) & (df_hp['matcher'] == matcher)]\n",
    "        unanswered = alg_matches[~alg_matches['correspondence'].isin(answered['correspondence'].tolist())][['correspondence', alg, 'real']]\n",
    "        last_P_pred = answered['P_hat'].iloc[[-1]].tolist()[0]\n",
    "        last_P_real = answered['P'].iloc[[-1]].tolist()[0]\n",
    "        last_F_pred = answered['F_hat'].iloc[[-1]].tolist()[0]\n",
    "        last_F_real = answered['F'].iloc[[-1]].tolist()[0]\n",
    "        answered[['targName', 'candName']] = answered['correspondence'].str.split(',', expand = True)\n",
    "        answered['candName'] = answered['candName'].str.replace('\\'', '').str.replace(')', '').str.strip()\n",
    "        answered['targName'] = answered['targName'].str.replace('\\'', '').str.replace('(', '').str.strip()\n",
    "        unanswered[['targName', 'candName']] = unanswered['correspondence'].str.split(',', expand = True)\n",
    "        unanswered['candName'] = unanswered['candName'].str.replace('\\'', '').str.replace(')', '').str.strip()\n",
    "        unanswered['targName'] = unanswered['targName'].str.replace('\\'', '').str.replace('(', '').str.strip()\n",
    "        max_rows = answered.groupby('candName')['pred'].max().to_frame(name = 'max').reset_index()\n",
    "        max_cols = answered.groupby('targName')['pred'].max().to_frame(name = 'max').reset_index()\n",
    "        unanswered_max_rows = unanswered.merge(max_rows, how = 'left', on = 'candName').fillna(0.0)\n",
    "        unanswered_max_cols = unanswered.merge(max_cols, how = 'left', on = 'targName').fillna(0.0)\n",
    "        other_vals_temp = [matcher,] + 8*[None,] + [alg] + 6*[None,] + 7*[1.0,]\n",
    "#         print(list(zip(other_cols, other_vals_temp)))\n",
    "#         THRESHOLD\n",
    "        df_rb_th_P_dynamic = unanswered[unanswered[alg] >= last_P_pred][['correspondence', 'real']]\n",
    "        df_rb_th_P_dynamic[other_cols] = pd.DataFrame([other_vals_temp], index = df_rb_th_P_dynamic.index)\n",
    "        df_rb_th['P_dynamic'] = pd.concat([df_rb_th['P_dynamic'], df_rb_th_P_dynamic])\n",
    "        df_rb_th_P_real = unanswered[unanswered[alg] >= last_P_real][['correspondence', 'real']]\n",
    "        df_rb_th_P_real[other_cols] = pd.DataFrame([other_vals_temp], index = df_rb_th_P_real.index)\n",
    "        df_rb_th['P_real'] = pd.concat([df_rb_th['P_real'], df_rb_th_P_real])\n",
    "        df_rb_th_F_dynamic = unanswered[unanswered[alg] >= 0.5*last_F_pred][['correspondence', 'real']]\n",
    "        df_rb_th_F_dynamic[other_cols] = pd.DataFrame([other_vals_temp], index = df_rb_th_F_dynamic.index)\n",
    "        df_rb_th['F_dynamic'] = pd.concat([df_rb_th['F_dynamic'], df_rb_th_F_dynamic])\n",
    "        df_rb_th_F_real = unanswered[unanswered[alg] >= 0.5*last_F_real][['correspondence', 'real']]\n",
    "        df_rb_th_F_real[other_cols] = pd.DataFrame([other_vals_temp], index = df_rb_th_F_real.index)\n",
    "        df_rb_th['F_real'] = pd.concat([df_rb_th['F_real'], df_rb_th_F_real])\n",
    "#         MAXDELTA        \n",
    "        df_rb_maxd_P_dynamic = unanswered_max_rows[unanswered_max_rows[alg] >= \n",
    "                                                   unanswered_max_rows['max'] - last_P_pred][['correspondence', 'real']]\n",
    "        df_rb_maxd_P_dynamic[other_cols] = pd.DataFrame([other_vals_temp], index = df_rb_maxd_P_dynamic.index)\n",
    "        df_rb_maxd['P_dynamic'] = pd.concat([df_rb_maxd['P_dynamic'], df_rb_maxd_P_dynamic])\n",
    "        df_rb_maxd_P_real = unanswered_max_rows[unanswered_max_rows[alg] >= \n",
    "                                                   unanswered_max_rows['max'] - last_P_real][['correspondence', 'real']]\n",
    "        df_rb_maxd_P_real[other_cols] = pd.DataFrame([other_vals_temp], index = df_rb_maxd_P_real.index)\n",
    "        df_rb_maxd['P_real'] = pd.concat([df_rb_maxd['P_real'], df_rb_maxd_P_real])\n",
    "        df_rb_maxd_F_dynamic = unanswered_max_rows[unanswered_max_rows[alg] >= \n",
    "                                                   unanswered_max_rows['max'] - 0.5*last_F_pred][['correspondence', 'real']]\n",
    "        df_rb_maxd_F_dynamic[other_cols] = pd.DataFrame([other_vals_temp], index = df_rb_maxd_F_dynamic.index)\n",
    "        df_rb_maxd['F_dynamic'] = pd.concat([df_rb_maxd['F_dynamic'], df_rb_maxd_F_dynamic])\n",
    "        df_rb_maxd_F_real = unanswered_max_rows[unanswered_max_rows[alg] >= \n",
    "                                                   unanswered_max_rows['max'] - 0.5*last_F_real][['correspondence', 'real']]\n",
    "        df_rb_maxd_F_real[other_cols] = pd.DataFrame([other_vals_temp], index = df_rb_maxd_F_real.index)\n",
    "        df_rb_maxd['F_real'] = pd.concat([df_rb_maxd['F_real'], df_rb_maxd_F_real])   \n",
    "#         MAXDELTA COLUMN        \n",
    "        df_rb_maxdcol_P_dynamic = unanswered_max_cols[unanswered_max_cols[alg] >= \n",
    "                                                   unanswered_max_cols['max'] - last_P_pred][['correspondence', 'real']]\n",
    "        df_rb_maxdcol_P_dynamic[other_cols] = pd.DataFrame([other_vals_temp], index = df_rb_maxdcol_P_dynamic.index)\n",
    "        df_rb_maxdcol['P_dynamic'] = pd.concat([df_rb_maxdcol['P_dynamic'], df_rb_maxdcol_P_dynamic])\n",
    "        df_rb_maxdcol_P_real = unanswered_max_cols[unanswered_max_cols[alg] >= \n",
    "                                                   unanswered_max_cols['max'] - last_P_real][['correspondence', 'real']]\n",
    "        df_rb_maxdcol_P_real[other_cols] = pd.DataFrame([other_vals_temp], index = df_rb_maxdcol_P_real.index)\n",
    "        df_rb_maxdcol['P_real'] = pd.concat([df_rb_maxdcol['P_real'], df_rb_maxdcol_P_real])\n",
    "        df_rb_maxdcol_F_dynamic = unanswered_max_cols[unanswered_max_cols[alg] >= \n",
    "                                                   unanswered_max_cols['max'] - 0.5*last_F_pred][['correspondence', 'real']]\n",
    "        df_rb_maxdcol_F_dynamic[other_cols] = pd.DataFrame([other_vals_temp], index = df_rb_maxdcol_F_dynamic.index)\n",
    "        df_rb_maxdcol['F_dynamic'] = pd.concat([df_rb_maxdcol['F_dynamic'], df_rb_maxdcol_F_dynamic])\n",
    "        df_rb_maxdcol_F_real = unanswered_max_cols[unanswered_max_cols[alg] >= \n",
    "                                                   unanswered_max_cols['max'] - 0.5*last_F_real][['correspondence', 'real']]\n",
    "        df_rb_maxdcol_F_real[other_cols] = pd.DataFrame([other_vals_temp], index = df_rb_maxdcol_F_real.index)\n",
    "        df_rb_maxdcol['F_real'] = pd.concat([df_rb_maxdcol['F_real'], df_rb_maxdcol_F_real]) \n",
    "#         DOMINANTS       \n",
    "        df_rb_dom_P_dynamic = unanswered_max_rows[(unanswered_max_rows[alg] >= \n",
    "                                                unanswered_max_rows['max'] - last_P_pred) &\n",
    "                                                (unanswered_max_cols[alg] >= \n",
    "                                                unanswered_max_cols['max'] - last_P_pred)][['correspondence', 'real']]\n",
    "        df_rb_dom_P_dynamic[other_cols] = pd.DataFrame([other_vals_temp], index = df_rb_dom_P_dynamic.index)\n",
    "        df_rb_dom['P_dynamic'] = pd.concat([df_rb_dom['P_dynamic'], df_rb_dom_P_dynamic])\n",
    "        df_rb_dom_P_real = unanswered_max_rows[(unanswered_max_rows[alg] >= \n",
    "                                                unanswered_max_rows['max'] - last_P_real) &\n",
    "                                                (unanswered_max_cols[alg] >= \n",
    "                                                unanswered_max_cols['max'] - last_P_real)][['correspondence', 'real']]\n",
    "        df_rb_dom_P_real[other_cols] = pd.DataFrame([other_vals_temp], index = df_rb_dom_P_real.index)\n",
    "        df_rb_dom['P_real'] = pd.concat([df_rb_dom['P_real'], df_rb_dom_P_real])\n",
    "        df_rb_dom_F_dynamic = unanswered_max_rows[(unanswered_max_rows[alg] >= \n",
    "                                                unanswered_max_rows['max'] - 0.5*last_F_pred) &\n",
    "                                                (unanswered_max_cols[alg] >= \n",
    "                                                unanswered_max_cols['max'] - 0.5*last_F_pred)][['correspondence', 'real']]\n",
    "        df_rb_dom_F_dynamic[other_cols] = pd.DataFrame([other_vals_temp], index = df_rb_dom_F_dynamic.index)\n",
    "        df_rb_dom['F_dynamic'] = pd.concat([df_rb_dom['F_dynamic'], df_rb_dom_F_dynamic])\n",
    "        df_rb_dom_F_real = unanswered_max_rows[(unanswered_max_rows[alg] >= \n",
    "                                                unanswered_max_rows['max'] - 0.5*last_F_real) &\n",
    "                                                (unanswered_max_cols[alg] >= \n",
    "                                                unanswered_max_cols['max'] - 0.5*last_F_real)][['correspondence', 'real']]\n",
    "        df_rb_dom_F_real[other_cols] = pd.DataFrame([other_vals_temp], index = df_rb_dom_F_real.index)\n",
    "        df_rb_dom['F_real'] = pd.concat([df_rb_dom['F_real'], df_rb_dom_F_real]) \n",
    "#         STATICS:\n",
    "        for num in thresholds:\n",
    "#         THRESHOLD:\n",
    "            df_rb_th_temp = unanswered[unanswered[alg] >= num][['correspondence', 'real']]\n",
    "            df_rb_th_temp[other_cols] = pd.DataFrame([other_vals_temp], index = df_rb_th_temp.index)\n",
    "            df_rb_th[str(num)] = pd.concat([df_rb_th[str(num)], df_rb_th_temp])\n",
    "#             MAXDELTA\n",
    "            df_rb_maxd_temp = unanswered_max_rows[unanswered_max_rows[alg] >= \n",
    "                                                       unanswered_max_rows['max'] - num][['correspondence', 'real']]\n",
    "            df_rb_maxd_temp[other_cols] = pd.DataFrame([other_vals_temp], index = df_rb_maxd_temp.index)\n",
    "            df_rb_maxd[str(num)] = pd.concat([df_rb_maxd[str(num)], df_rb_maxd_temp])\n",
    "#             MAXDELTA COLUMN\n",
    "            df_rb_maxdcol_temp = unanswered_max_cols[unanswered_max_cols[alg] >= \n",
    "                                                       unanswered_max_cols['max'] - num][['correspondence', 'real']]\n",
    "            df_rb_maxdcol_temp[other_cols] = pd.DataFrame([other_vals_temp], index = df_rb_maxdcol_temp.index)\n",
    "            df_rb_maxdcol[str(num)] = pd.concat([df_rb_maxdcol[str(num)], df_rb_maxdcol_temp])\n",
    "#             DOMINANTS\n",
    "            df_rb_dom_temp = unanswered_max_rows[(unanswered_max_rows[alg] >= \n",
    "                                                unanswered_max_rows['max'] - num) &\n",
    "                                                (unanswered_max_cols[alg] >= \n",
    "                                                unanswered_max_cols['max'] - num)][['correspondence', 'real']]\n",
    "            df_rb_dom_temp[other_cols] = pd.DataFrame([other_vals_temp], index = df_rb_dom_temp.index)\n",
    "            df_rb_dom[str(num)] = pd.concat([df_rb_dom[str(num)], df_rb_dom_temp])  \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_df_rb(df_rb_0, df):\n",
    "    clfs = df['clf'].unique().tolist()\n",
    "    regs = df['reg'].unique().tolist()\n",
    "    new_df_rb = None\n",
    "    for clf in clfs:\n",
    "        for reg in regs:\n",
    "            temp_df_rb = df_rb_0.copy() \n",
    "            temp_df_rb['alg'] = df_rb_0['alg_matcher'] + ' ' + clf + ' ' + reg\n",
    "            new_df_rb = pd.concat([new_df_rb, temp_df_rb])\n",
    "    return new_df_rb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for RB, df_rb in df_rb_th.items():\n",
    "    df_rb = fix_df_rb(df_rb, df_hp)\n",
    "    full_df = pd.concat([df_hp, df_rb])\n",
    "    _ = evaluate(full_df.rename(columns={'pred': 'temp', 'pred_R': 'pred'}), 'hp_target_R_rb_threshold_' + RB)\n",
    "    _ = evaluate(full_df.rename(columns={'pred': 'temp', 'pred_P_static': 'pred'}), 'hp_target_P_static_rb_threshold_' + RB)\n",
    "    _ = evaluate(full_df.rename(columns={'pred': 'temp', 'pred_P_dynamic': 'pred'}), 'hp_target_P_dynamic_rb_threshold_' + RB)\n",
    "    _ = evaluate(full_df.rename(columns={'pred': 'temp', 'pred_F_static': 'pred'}), 'hp_target_F_static_rb_threshold_' + RB)\n",
    "    _ = evaluate(full_df.rename(columns={'pred': 'temp', 'pred_F_dynamic': 'pred'}), 'hp_target_F_dynamic_rb_threshold_' + RB)\n",
    "    \n",
    "for RB, df_rb in df_rb_maxd.items():\n",
    "    full_df = pd.concat([df_hp, df_rb])\n",
    "    _ = evaluate(full_df.rename(columns={'pred': 'temp', 'pred_R': 'pred'}), 'hp_target_R_rb_maxd_' + RB)\n",
    "    _ = evaluate(full_df.rename(columns={'pred': 'temp', 'pred_P_static': 'pred'}), 'hp_target_P_static_rb_maxd_' + RB)\n",
    "    _ = evaluate(full_df.rename(columns={'pred': 'temp', 'pred_P_dynamic': 'pred'}), 'hp_target_P_dynamic_rb_maxd_' + RB)\n",
    "    _ = evaluate(full_df.rename(columns={'pred': 'temp', 'pred_F_static': 'pred'}), 'hp_target_F_static_rb_maxd_' + RB)\n",
    "    _ = evaluate(full_df.rename(columns={'pred': 'temp', 'pred_F_dynamic': 'pred'}), 'hp_target_F_dynamic_rb_maxd_' + RB)\n",
    "\n",
    "for RB, df_rb in df_rb_maxdcol.items():\n",
    "    full_df = pd.concat([df_hp, df_rb])\n",
    "    _ = evaluate(full_df.rename(columns={'pred': 'temp', 'pred_R': 'pred'}), 'hp_target_R_rb_maxdcol_' + RB)\n",
    "    _ = evaluate(full_df.rename(columns={'pred': 'temp', 'pred_P_static': 'pred'}), 'hp_target_P_static_rb_maxdcol_' + RB)\n",
    "    _ = evaluate(full_df.rename(columns={'pred': 'temp', 'pred_P_dynamic': 'pred'}), 'hp_target_P_dynamic_rb_maxdcol_' + RB)\n",
    "    _ = evaluate(full_df.rename(columns={'pred': 'temp', 'pred_F_static': 'pred'}), 'hp_target_F_static_rb_maxdcol_' + RB)\n",
    "    _ = evaluate(full_df.rename(columns={'pred': 'temp', 'pred_F_dynamic': 'pred'}), 'hp_target_F_dynamic_rb_maxdcol_' + RB)\n",
    "\n",
    "for RB, df_rb in df_rb_dom.items():\n",
    "    full_df = pd.concat([df_hp, df_rb])\n",
    "    _ = evaluate(full_df.rename(columns={'pred': 'temp', 'pred_R': 'pred'}), 'hp_target_R_rb_dom_' + RB)\n",
    "    _ = evaluate(full_df.rename(columns={'pred': 'temp', 'pred_P_static': 'pred'}), 'hp_target_P_static_rb_dom_' + RB)\n",
    "    _ = evaluate(full_df.rename(columns={'pred': 'temp', 'pred_P_dynamic': 'pred'}), 'hp_target_P_dynamic_rb_dom_' + RB)\n",
    "    _ = evaluate(full_df.rename(columns={'pred': 'temp', 'pred_F_static': 'pred'}), 'hp_target_F_static_rb_dom_' + RB)\n",
    "    _ = evaluate(full_df.rename(columns={'pred': 'temp', 'pred_F_dynamic': 'pred'}), 'hp_target_F_dynamic_rb_dom_' + RB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
